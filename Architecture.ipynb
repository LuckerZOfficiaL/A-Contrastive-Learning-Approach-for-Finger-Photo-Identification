{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LuckerZOfficiaL/A-Contrastive-Learning-Approach-for-Finger-Photo-Identification/blob/main/Architecture.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Architecture Implementation"
      ],
      "metadata": {
        "id": "qEvd0QzqhMoH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.init as init\n",
        "import torchvision.models as models"
      ],
      "metadata": {
        "id": "Q_Ys14iLhP0l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ResnetClassifier(nn.Module):\n",
        "  def __init__(self, num_classes=100, hidden_size=256, initialize=\"xavier\"):\n",
        "    super(ResnetClassifier, self).__init__()\n",
        "    self.conv_1to3 = nn.Conv2d(1, 3, kernel_size=1, stride=1, padding=0)\n",
        "    self.pretrained_model = models.resnet18(pretrained=True)\n",
        "    #self.intermediate_norm = nn.BatchNorm1d(1000, affine=False) # batch norm doesn't work when batch size = 1, so let's use layerNorm\n",
        "    self.intermediate_norm = nn.LayerNorm(1000)\n",
        "    self.projector = nn.Linear(1000, hidden_size)\n",
        "    self.final_norm = nn.LayerNorm(hidden_size)\n",
        "    self.dropout = nn.Dropout(0.2)\n",
        "    self.activation = nn.GELU()\n",
        "    self.fc = nn.Linear(hidden_size, num_classes)\n",
        "    self.softmax = nn.Softmax(dim=1)\n",
        "\n",
        "    if initialize == \"kaiming\":\n",
        "      init.kaiming_uniform_(self.projector.weight, mode='fan_in', nonlinearity='leaky_relu')\n",
        "      init.kaiming_uniform_(self.fc.weight, mode='fan_out')\n",
        "      init.constant_(self.fc.bias, 0)\n",
        "    if initialize == \"xavier\":\n",
        "      init.xavier_uniform_(self.projector.weight)\n",
        "      init.xavier_uniform_(self.fc.weight)\n",
        "      init.constant_(self.fc.bias, 0)\n",
        "\n",
        "\n",
        "  def forward(self, x):\n",
        "      if x.size()[1] == 1:\n",
        "        x = self.conv_1to3(x)\n",
        "      x = self.pretrained_model(x)\n",
        "      x = self.intermediate_norm(x)\n",
        "      x = self.projector(x)\n",
        "      x = self.final_norm(x)\n",
        "      x = self.activation(x)\n",
        "      x = self.dropout(x)\n",
        "      x = self.fc(x)\n",
        "      x = self.softmax(x)\n",
        "      return x\n",
        "  def forward_logits(self, x):\n",
        "      if x.size()[1] == 1:\n",
        "        x = self.conv_1to3(x)\n",
        "      x = self.pretrained_model(x)\n",
        "      x = self.intermediate_norm(x)\n",
        "      #x = self.activation(x)\n",
        "      x = self.projector(x)\n",
        "      x = self.final_norm(x)\n",
        "      x = self.activation(x)\n",
        "      x = self.dropout(x)\n",
        "      x = self.fc(x)\n",
        "      return x\n",
        "  def forward_projector(self, x):\n",
        "      if x.size()[1] == 1:\n",
        "        x = self.conv_1to3(x)\n",
        "      x = self.pretrained_model(x)\n",
        "      x = self.intermediate_norm(x)\n",
        "      x = self.projector(x)\n",
        "      return x\n",
        "  def forward_backbone(self, x):\n",
        "      if x.size()[1] == 1:\n",
        "        x = self.conv_1to3(x)\n",
        "      x = self.pretrained_model(x)\n",
        "      return x\n"
      ],
      "metadata": {
        "id": "YfoILXoyQA32"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"x = torch.rand((8, 1, 123, 331))\n",
        "model = ResnetClassifier(num_classes=100, hidden_size=256, initialize=\"xavier\")\n",
        "model.forward_projector(x).shape\"\"\""
      ],
      "metadata": {
        "id": "sfzYvyLMhoKv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ce7672ab-7b2b-48e4-a0d7-4b31721b7f90"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([8, 256])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    }
  ]
}